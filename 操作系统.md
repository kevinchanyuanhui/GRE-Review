## 第1章 计算机系统概述

### 1.1 操作系统的基本概念

#### 1.1.2 操作系统的特征

​	（1）并发	（2）共享(**互斥共享**和**同时访问**)	（3）虚拟(**时分复用**和**空分复用**)	（4）异步

**【注】**现代操作系统最基本的两个特征是：**并发**与**共享**

#### 1.1.3 操作系统的目标和功能

1. **操作系统作为计算机系统资源的管理者**

**（1）处理机管理**

&emsp;&emsp;在多道程序环境下，处理机的分配和运行都是以进程(或线程)作为基本单位，因而**对处理机的管理可归结为对进程的管理**。

**主要功能**：进程控制、进程同步、进程通信、死锁处理、处理机调度等。

**（2）存储器管理**

&emsp;&emsp;方便用户使用及提高内存的利用率。

**主要功能**：内存分配、地址映射、内存保护与共享、内存扩充等。

**（3）文件管理**

&emsp;&emsp;计算机中的信息都是以文件的形式存在的，操作系统中负责文件管理的部分称为**文件系统**。

**主要功能**：文件存储空间的管理、目录管理及文件读写管理和保护等。

**（4）设备管理**

&emsp;&emsp;设备管理的主要任务是完成用户的I/O请求，方便用户使用各种设备，并提高设备的利用率。

**主要功能**：缓冲管理、设备管理、设备处理、虚拟设备

2. **操作系统作为用户与计算机硬件系统之间的接口**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-23</font>

&emsp;&emsp;为方便用户使用计算机，操作系统还提供了用户接口。一类是**命令接口**，用户利用这些操作命令来组织和控制作业的执行；另一类是**程序接口**，编程人员使用它们来请求操作系统服务。

**（1）命令接口**

&emsp;&emsp;按作业控制方式不同，可将命令接口分为**联机命令接口**和**脱机命令接口**。

- **联机命令接口**

&emsp;&emsp;联机命令接口又称**交互式命令接口**，适用于**分时或实时系统的接口**。它由一组**键盘操作命令**组成。用户通过控制台或终端输入操作系统命令，向系统提出各种服务要求。**操作系统直接控制作业的运行**。

- **脱机命令接口**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2016-23</font>

&emsp;&emsp;脱机命令接口又称为**批处理命令接口**，适用于**批处理系统**，它由一组**作业控制命令(或作业控制语句)**组成。脱机用户不能直接干预作业的运行，而应事先用相应的作业控制命令写成一份作业操作说明书，连同作业一起交给系统。**操作系统间接控制作业的运行**。

**（2）程序接口**

&emsp;&emsp;程序接口由**一组系统调用命令(简称系统调用,也称为广义指令)**组成。用户通过在程序中使用这些系统调用来请求操作系统为其提供服务。用户在程序中可直接使用这组系统调用命令向系统提出各种服务要求，如**使用各种外部设备、进行有关磁盘文件的操作、申请分配和回收内存**及其它各种控制要求等。

**【注】**当前最流行的图像用户界面(GUI)，即图形接口，用户通过鼠标和键盘，在图形界面上单击或使用快捷键，就能很方便使用操作系统。**GUI图形接口不是操作系统的一部分，但图形接口所调用的系统调用命令是操作系统的一部分**。

- **操作系统用作扩充机器**

&emsp;&emsp;没有任何软件支持的计算机称为裸机。裸机在最里层，操作系统在最外层。我们将把覆盖了软件的机器称为扩充机器或虚拟机。



### 1.2 操作系统的发展与分类

#### 1.2.1 手工操作阶段(此阶段无操作系统)

#### 1.2.2 批处理阶段(操作系统开始阶段)

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2012-29,2016-23,2017-28</font>

&emsp;&emsp;为了**解决人机矛盾及CPU和I/O设备之间速度不匹配的矛盾**，出现了批处理系统。它按发展历程又分为单道批处理系统、多道批处理系统(多道程序设计技术出现以后)。

1. **单道批处理系统**

&emsp;&emsp;系统对作业的处理是成批进行的，但**内存中始终保持一道作业**，单道批处理系统是在**解决人机矛盾及CPU和I/O设备速率不匹配的矛盾**中形成的。

- **主要特点**

<img src="./操作系统/1.2.2-1.png" alt="1.2.2-1" style="zoom:90%;" />

- **缺点**：在内存中运行的作业发出I/O请求时，高速的CPU便处于等待低速的I/O完成状态。



2. **多道批处理系统**

&emsp;&emsp;多道程序设计技术允许多个程序同时进入内存并允许这些它们在CPU中交替运行，这些程序**共享系统中的各种硬/软件资源**。当一道程序因I/O暂停时，CPU便立即转去运行另一道程序。

- **主要特点**

<img src="./操作系统/1.2.2-2.png" alt="1.2.2-2" style="zoom:90%;" />

**【注】中断技术**使得多道批处理系统的I/O设备可与CPU并行工作

- **多道程序设计技术需要解决下列问题**

<img src="./操作系统/1.2.2-3.png" alt="1.2.2-3" style="zoom:90%;" />

- **优点 VS 缺点**

**1）优点**：资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大，CPU和其他资源保持“忙碌”状态。

**2）缺点**：用户响应的时间较长，不提供人机交互能力，用户既不能了解自己程序的运行情况，又不能控制计算机。

**【注】**引入多道程序设计之后，程序的执行就失去**封闭性**和**顺序性**。



#### 1.2.3 分时操作系统

&emsp;&emsp;所谓分时技术，是指把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分给联机作业使用。

&emsp;&emsp;分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时与主机进行交互操作而互不干扰。

&emsp;&emsp;分时操作系统也**支持多道程序设计的系统**，但它不同于多道批处理系统。多道批处理是实现作业自动控制而无须人工干预的系统，而分时系统是实现**人机交互**的系统。

- **主要特点**

<img src="./操作系统/1.2.3-1.png" alt="1.2.3-1" style="zoom:80%;" />

#### 1.2.4 实时操作系统



#### 1.2.5 网络操作系统和分布式计算机系统



#### 1.2.6 个人计算机操作系统



### 1.3 操作系统运行的环境

#### 1.3.1 操作系统的运行机制





#### 1.3.2 中断和异常的概念

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2012-24,2015-22,2016-22</font>

&emsp;&emsp;发送中断或异常时，运行用户态的CPU会立即进入核心态，这是通过**硬件实现**的。

- **中断**

&emsp;&emsp;中断也称为**外中断**，指来自CPU执行指令以外的事情的发生，如设备发出的I/O结束中断，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入/输出请求，同时让完成输入/输出处理后的程序继续运行。

**【注】**外部中断处理过程中，**PC值由中断隐指令自动保存，而通用寄存器内容由操作系统保存**。

&emsp;&emsp;**时钟中断**：表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。这一类中断通常是与当前程序运行无关的事件，即它们与当前处理机运行的程序无关。

- **异常**

&emsp;&emsp;异常也称为**内中断**、**例外**或**陷入(trap)**，指源自**CPU执行指令或内存**内部的事件，如**程序的非法操作码、地址越界、算术溢出、虚存系统的缺页以及专门的陷入指令引起的事件**。对异常的处理一般要依赖与当前程序的运行现场，而且**异常不能被屏蔽**，一旦出现立即处理。

**【注】**内中断的产生与当前执行指令相关、它的检测是由CPU内部逻辑实现的，它的响应发生在指令执行过程中。

<img src="./操作系统/3.2.1-1.png" alt="3.2.1-1" style="zoom:90%;" />

- **中断处理和子程序调用的区别**

&emsp;&emsp;子程序调用只需**保护断点(程序计数器)**，即该指令的下一条指令的地址；中断调用子程序不仅要保护断点，还要保护**程序状态字寄存器的内容 PSW**（有些机器也称标志寄存器 FLAGS）。另外，两者还需保存**通用数据寄存器**和**通用地址寄存器**的内容。



#### 1.3.3 系统调用

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2011-24,2012-23,2013-28,2014-25,2015-24,2017-24</font>

&emsp;&emsp;所谓系统调用，是指用户在程序中调用操作系统所提供的一些子功能，**系统调用可视为特殊的公共子程序**。系统的各种共享资源都由操作系统统一掌管，因此在用户程序中，**凡是与资源有关的操作(如存储分配、进行I/O传输及管理文件等)，都必须通过系统调用方式向操作系统提出服务请求**，并由操作系统代完成。

- **系统调用按功能分类**

<img src="./操作系统/1.3.3-1.png" alt="1.3.3-1" style="zoom:90%;" />

- **核心态与用户态**

&emsp;&emsp;系统调用需要**使用某些特权指令**才能完成，需要由操作系统**内核程序负责完成**，即要运行在核心态。用户程序可以执行**陷入指令(又称仿管指令或trap指令)**来发起系统调用，请求操作系统提供服务。可以这么理解，用户程序执行”陷入指令“，相当于把CPU的使用权主动交给操作系统内核程序(CPU的状态会从用户态进入核心态)，之后操作系统内核程序再对系统调用请求做出相应处理。处理完成后，操作系统内核程序又把CPU的使用权还给用户程序(即CPU状态会从核心态回到用户态)。

&emsp;&emsp;这样设计的目的是用户程序不能直接执行对系统影响非常大的操作，必须通过系统调用的方式请求操作系统代之执行，保证系统的稳定性和安全性，防止用户程序更改或访问重要的系统资源，影响其它进程运行。

<img src="./操作系统/1.3.3-2.png" alt="1.3.3-2" style="zoom:90%;" />

- **用户态转向核心态的例子【重点】**

1）用户程序要求操作系统的服务，即系统调用，如**read系统调用**

2）发生一次中断

3）用户程序中发生了一个错误状态，如**整数除零**操作

4）用户程序中企图执行一条特权指令

5）从核心态转向用户态由一条指令实现，这条指令也是特权命令，一般是中断返回指令。

6）进程状态变化，如由进程的运行态转向等待态

**【注】**从用户态进入核心态，不仅状态需要切换，而且所用的堆栈也可能需要用户堆栈切换为系统堆栈，但这个系统堆栈也是属于该进程的。

&emsp;&emsp;若程序的运行是由用户态转到核心态，则会用到**访管指令**，**访管指令是在用户态使用的，所以，它不可能是特权指令**。

**【注】**做题时应该清楚哪些指令或事件是在用户态执行的，哪些是在核心态执行的，哪些是可以将用户态转为核心态的。



## 第2章 进程的管理

### 2.1 进程与线程

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-26</font>

#### 2.1.1 进程的概念和特征

1. **进程的概念**

&emsp;&emsp;在多道程序环境下，允许多个程序并发执行，此时它们将失去**封闭性**，并具有**间断性**及**不可再现性**的特征，为此引入了进程概念。

**【注1】程序段**、**相关数据段**和**PCB**三部分构成了**进程映象(进程实体)**。**PCB是进程存在的唯一标志**。所谓**创建进程，实际上是创建进程映象中的PCB；而撤销进程，实际上是撤销进程的PCB**。

**【注2】进程实体是静态的，进程是动态的**。我们可以把传统的操作系统中的进程定义为：“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位”。

2. **进程的特征**

   **1）动态性**。进程是一次执行，它有着创建、活动、暂停、终止等过程，具有一定的生命周期，是动态地产生、变化和消亡的。**动态性是进程最基本的特征**。

   **2）并发性**。指多个进程同时存在于内存中，能在一段时间内同时运行。**并发性是进程的重要特征**。

   **3）独立性**。指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立PCB的程序，都不能作为一个独立的单位参与运行。

   **4）异步性**。由于进程的相互制约，使得进程具有执行的间断性，即进程按各自独立的、不可知的速度推进。

   **5）结构性**。每个进程都配置一个PCB对其描述。进程实体都是由**程序段**、**数据段**和**进程控制块**三部分组成的。

#### 2.1.2 进程的状态与转换

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-23,2014-26,2015-25</font>

**1）运行态**：进程正在处理机上运行。**在单处理机环境下，每个时刻最多只有一个进程处于运行态**。

**2）就绪态**：进程已处于准备运行状态，即进程获得了除处理机外的一切所需资源，一旦得到处理机即可运行。

**3）阻塞态**：又称为等待态。进程正在等待某一事件而暂停运行，如等待某资源为可用(不包括处理机)或等待输入/输出完成。即使处理机空闲，该进程也不能运行。

**4）创建态**：进程正在被创建，尚未转到就绪态。创建进程通常需要多个步骤：首先申请一个空白的PCB，并向PCB中填写一些控制和管理进程的信息；然后由系统为该进程分配运行时所需的必要资源，最后把该进程转入就绪态。

**5）结束态**：进程正在从系统中消失，可能是进程正常结束或其它原因中断退出运行，进程需要结束运行时，系统首先必须置该进程为结束态，然后再进一步处理资源释放和回收工作。

- **五种基本状态之间的转换**

<img src="./操作系统/2.1.2-1.png" alt="2.1.2-1" style="zoom:90%;" />

**（1）就绪态->运行态**：处于就绪的进程被调度后，获得处理机资源(分派处理机时间片)，于是进程就由就绪态转为运行态。

**（2）运行态->就绪态**：处于运行态的进程在时间片用完后，不得不退出处理机，从而进程由运行态转为就绪态。此外，在可剥夺的操作系统中，当有更高优先级的进程就绪时，调度程序将正在执行的进程转为就绪态，让更高优先级的进程执行。

**（3）运行态->阻塞态**：进程请求某一资源(如外设)的使用和分配或等待某一事件的发生(如I/O操作的完成)时，它就从运行态转阻塞态。

**（4）阻塞态->就绪态**：进程等待的事件到来时，如I/O操作结束或中断结束时，中断处理程序必须把相应进程的状态由阻塞态转换为就绪态。

**【注】进程从运行态转变为阻塞态是主动行为，而从阻塞态变成就绪态是被动行为**，需要其它相关进程的协助。



#### 2.1.3 进程控制

&emsp;&emsp;在操作系统中，**一般把进程控制的程序称为原语**，原语的特点是执行期间不允许被中断，它是一个不可被分割的基本单位。

1. **进程的创建**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-24</font>

- **子进程与父进程**

<img src="./操作系统/2.1.3-1.png" alt="2.1.3-1" style="zoom:90%;" />

- **引起进程创建的事件**

终端用户登录、作业调度、系统提供服务、用户程序的应用请求等

- **操作系统创建一个新进程的过程**

1）为新进程分配一个唯一的进程标识号，并申请一个空白的PCB(PCB是有限的)。**若PCB申请失败，则创建失败**。

2）为进程分配资源，为新进程的程序和数据及用户栈分配必要的内存空间(在PCB中体现)。

**【注】**若资源不足(如内存空间)，则并不是创建失败，而是处于“等待态”或称为“阻塞态”，**等待的是内存这个资源**。

3）初始化PCB，主要包括初始化**标志信息**、初始化**状态信息**和初始化处理机**控制信息**，以及设置**进程的优先级**等。

4）若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待被调度运行。



2. **进程的终止**

- **引起进程终止的事件**

**1）正常结束**：表示进程的任务以及完成并准备退出。

**2）异常结束**：表示进程运行时，发送了某种异常事件，使程序无法继续运行，如**存储区越界、非法指令、特权指令错、保护错、I/O故障**等。

**3）外界干预**：指进程应外界的请求而终止运行，如**操作员或操作系统干预、父进程请求和父进程终止**。

- **进程终止的过程**![2.1.3-2](./操作系统/2.1.3-2.png)



3. **进程的阻塞和唤醒**

- **引起进程由执行态变为阻塞态的事件**

&emsp;&emsp;正在执行的进程，由于期待的某些事件未发生，如请**求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作可做**等，由系统自动执行**阻塞原语(Block)**，使自己由运行态变为阻塞态。当被阻塞进程所期待的事件出现时，由有关进程调用**唤醒原语(Wakeup)**，将等待该事件的进程唤醒。

- **阻塞原语的执行过程**

<img src="./操作系统/2.1.3-3.png" alt="2.1.3-3" style="zoom:80%;" />

- **唤醒原语的执行过程**

<img src="./操作系统/2.1.3-4.png" alt="2.1.3-4" style="zoom:80%;" />

**【注】**阻塞原语和唤醒原语是一对作用刚好相反的原语，必须**成对使用**。Block原语是由被阻塞进程自我调用实现的，而Wakeup原语则是由一个与被唤醒进程合作或被其它相关进程调用实现的。

4. **进程切换**

&emsp;&emsp;进程的切换是指处理机从一个进程的运行跳到另一个进程上运行。进程的切换是在内核的支持下实现的，因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

- **进程的切换过程**

<img src="./操作系统/2.1.3-5.png" alt="2.1.3-5" style="zoom:80%;" />

- **进程切换与处理机模式切换的区别**

<img src="./操作系统/2.1.3-6.png" alt="2.1.3-6" style="zoom:80%;" />

- **进程调度与切换的区别**

<img src="./操作系统/2.1.3-7.png" alt="2.1.3-7" style="zoom:80%;" />



#### 2.1.4 进程的组织



#### 2.1.5 进程的通信

&emsp;&emsp;进程的通信是指进程之间的信息交换。**PV操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式**。



#### 2.1.6 线程概念和多线程模型

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2011-25,2012-31</font>

1. **线程的基本概念**

&emsp;&emsp;引入进程的目的是为了更好地使用多道程序并发执行，提高资源利用率和系统吞吐率，增加并发程度；而**引进线程的目的则是为了减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能**。

**【注1】**线程由**线程ID**、**程序计数器**、**寄存器集合**和**堆栈**组成。

**【注2】线程是一个基本的CPU执行单元，也是程序执行流最小单元**。一个线程可以创建和撤销另一个线程，同一个进程中的多个线程可以并发执行。线程也有**就绪**、**阻塞**和**运行**三种状态。

2. **线程与进程的比较**

|              | 进程                                                   | 线程                                                         |
| ------------ | ------------------------------------------------------ | ------------------------------------------------------------ |
| **调度**     | 在没有引入线程的操作系统中，进程是独立调度的基本单位。 | 引入线程后的操作系统中，线程是独立调度的基本单位。在同一进程中线程的切换不会引起进程的切换，在不同进程中进行线程切换，会引起进程切换。 |
| **资源**     | 不管系统是否支持线程，进程是资源分配和拥有的基本单位   | 线程不拥有系统资源，但线程可以访问其所属进程的系统资源。     |
| **并发性**   | 进程间可以并发执行                                     | 线程间可以并发执行                                           |
| **系统开销** | 创建或撤销进程的开销远远大于创建或撤销线程时的开销     | 线程切换时只需保存和设置少量的寄存器内容                     |
| **地址空间** | 进程的地址空间之间互相独立                             | 同一进程的各线程间共享进程的地址空间                         |
| **通信**     | 进程间通信(IPC)需要进程同步和互斥手段的辅助            | 线程可以直接读/写进程数据段(如全局变量)来进行通信            |



3. **线程的属性**

1）**线程是一个轻型实体，它不拥有系统资源**，但每个线程都应有一个**唯一的标识符**和一**个线程控制块**，线程控制块记录了线程执行的寄存器和栈等现场状态。

2）不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。

3）同一进程中的各个线程共享该进程所拥有的资源。

4）线程是处理机的独立调度单位，多个线程是可以并发执行的。在单CPU的计算机系统中，各线程可以交替地占用CPU；在多CPU的计算机系统中，各线程可同时占用不同的CPU，若各个CPU同时为一个进程内的各线程服务，则可缩短进程的处理时间。

5）一个线程被创建后，便开始了它的生命周期，直至终止。线程在生命周期内会经历**阻塞态**、**就绪态**和**运行态**等各种状态变化。



4. **线程的实现方式**

- **用户级线程(User-Level Thread, ULT)**

&emsp;&emsp;在用户级线程中，**有关线程管理的所有工作都由应用程序完成**，**内核意识不到线程的存在**。应用程序可以通过使用线程库设计成多线程程序。通常，应该程序从单线程开始，在该线程中开始运行，在其运行时刻，可以通过调用线程库中派生例程创建一个在相同进程中运行的新线程。

- **内核级线程(Kernel-Level Thread, KLT)**

&emsp;&emsp;内核级程序中，线程管理所有工作由内核完成，应用程序没有线程管理的代码，**只有一个到内核级线程的编程接口**。内核为进程及其内部的每个线程维护上下文信息，调度也在内核基于线程架构的基础上完成。

&emsp;&emsp;有些系统中使用组合方式的多线程实现。线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些(小于等于用户级线程的数目)内核线程上。

<img src="./操作系统/2.1.6-1.png" alt="2.1.6-1" style="zoom:80%;" />



5. **多线程模型**

- **多对一模型**

&emsp;&emsp;将**多个用户级线程映射到一个内核级线程**，线程管理在用户空间完成。此模式中，**用户级线程对操作系统不可见(透明)**。

**优点**：线程管理是在用户空间进行的，因而效率比较高。

**缺点**：一个线程在使用内核服务时被阻塞，整个进程都会被阻塞；多个线程不能并行地运行在多处理机上。

- **一对一模型**

&emsp;&emsp;将用户级线程映射到一个内核级线程。

**优点**：当一个线程被阻塞后，允许另一个线序继续运行，所以并发能力较强。

**缺点**：每创建一个用户级线程都需要创建一个内核线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。

- **多对多模型**

&emsp;&emsp;将$n$个用户级线程映射到$m$个内核线程上，要求$m\le n$。

**特点**：多对多模型是多对一和一对一模型的折中，既克服了多对一模型并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程而开销太大的缺点。



### 2.2 处理机调度

#### 2.2.1 调度的概念

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2016-24</font>

1. **调度的基本概念**

&emsp;&emsp;在多道程序系统中，进程的数量往往多于处理机的个数，因此进程争用处理机在所难免。处理机调度是多道程序操作系统的基础，是操作系统设计的核心问题。

2. **调度的层次**

一个作业从提交开始直到完成，往往要经历以下三级调度。

<img src="./操作系统/2.2.1-1.png" alt="2.2.1-1" style="zoom:80%;" />

3. **三级调度的联系**

&emsp;&emsp;作业调度从外存的后备队列中选择一批作业进入内存，为它们建立进程，这些进程被送入就绪队列，进程调度从就绪队列中选出一个进程，把其状态改为运行态，把CPU分配给它。**中级调度是为了提高内存的利用率**，系统将那些暂时不能运行的进程挂起来。当内存空间宽松时，通过中级调度选择具备运行条件的进程，将其挂起。

<img src="./操作系统/2.2.1-2.png" alt="2.2.1-2" style="zoom:80%;" />

1）作业调度为进程活动做准备，进程调度使进程正常活动起来，中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。

2）**作业调度的次数少，中级调度次数略多，进程调度的频率最高**。

3）进程调度是最基本的，不可或缺。



#### 2.2.2 处理机调度的时机

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2012-20</font>

&emsp;&emsp;**进程调度**和**切换程序**是操作系统**内核程序**。请求调度事件发生后，才可能运行进程调度程序。调度了新的就绪进程后，才会进行进程间的切换。理论上这三件事应该顺序执行，但在实际设计中，操作系统内核程序运行时，若某时发生了引起进程调度的因素，则不一定能马上进行进程调度与切换。

- 线代操作系统中，**不能**进行进程的调度与切换的情况有以下几种：

（1）**在处理机中断的过程**。

（2）**进程在操作系统内核程序临界区中**。

（3）**其它需要完全屏蔽中断的原子操作过程中**。如加锁、解锁、中断保护现场、恢复等原子操作。

**【注】**当进程处于临界区时，说明进程正在占用处理机，只要不破坏临界资源的使用规则，是不会影响处理机调度的。

- **应该进行进程调度和切换**的情况如下：

（1）**发生引起调度条件且当前进程无法继续运行下去时，可以马上进行调度和切换**。属于**非剥夺调度**。

（2）**中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换**。属于**剥夺调度**。



#### 2.2.3 进程调度的方法

1）非剥夺调度方法，又称非抢占方式

2）剥夺调度方法，又称抢占方式



#### 2.2.4 调度的基本原则



#### 2.2.5 典型的调度算法

1. **先来先服务(FCFS)调度算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2017-23</font>

&emsp;&emsp;FCFS调度算法**既可以用于作业调度，又可以用于进程调度**。在作业调度中，算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。

> 假设系统中有4个作业，它们的提交时间分别是8, 8.4, 8.8, 9，运行时间分别是2, 1, 0.5, 0.2，系统采用FCFS调度算法，这组作业的**平均等待时间**、**平均周转时间**和**带权周转时间**如图

<img src="./操作系统/2.2.5-1.png" alt="2.2.5-1" style="zoom:80%;" />

**特点**：算法简单，但效率低；**对长作业比较有利，但对短作业不利**(相对于SJF和高响应比)；**有利于CPU繁忙型作业，不利于I/O繁忙型作业**。

**【注1】**周转时间 = 等待时间+执行时间 = 完成时间 - 提交时间

**【注2】**FCFS有利于CPU繁忙型的作业，而不利于I/O繁忙型的作业



2. **短作业(SJF)调度算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2017-23</font>

&emsp;&emsp;短作业(进程)优先调度算法是指**对短作业(进程)优先调度的算法**。短作业优先(SJF)调度算法从后备队列中选择一个或若干估计运行时间最短作业，将它们调入内存运行。

<img src="./操作系统/2.2.5-2.png" alt="2.2.5-2" style="zoom:80%;" />

**特点**：

1）对长作业不利，**会导致“饥饿”现象**。

2）该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业及时处理。

3）由于作业长短只是根据用户提供的估计执行时间而定的，而用户又可能会有意识或无意识缩短其作业的估计运行时间，致使该算法**不一定能真正做到短作业优先调度**。

**【注】SJF调度算法的平均等待时间、平均周转时间最少**。



3. **优先级调度算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2013-31</font>

<font color='#0099ff' size=5 face="黑体">大题：</font><font color='#FF0000' size=4 face="黑体">2016-46</font>

&emsp;&emsp;优先级调度算法又称为优先权调度算法，它**既可以用于作业调度，又可以用于进程调度**。该算法中的**优先级用于描述作业运行的紧迫程度**。

- **根据新的更高优先级进程能否抢占正在执行的进程**，可将该调度算法分为如下两种：

**1）非剥夺式优先级调度算法**：当一个进程正在处理机上运行时，即使有更为重要或紧迫的进程进入就绪队列，仍然让正在运行的程序继续运行，直到由于其自身原因让出处理机时(任务完成或等待事件)，才把处理机分配给更重要或紧迫的进程。

**2）剥夺式优先级调度算法**：当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。

- **根据进程创建后其优先级是否可以改变**，可以将进程优先级分为以下两种：

**1）静态优先级**：优先级是创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有**进程类型**、**进程对资源的要求**、**用户要求**。

**2）动态优先级**：在进程运行的过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据有**进程占有CPU时间的长短**、**就绪进程等待CPU时间的长短**。

- 一般来说，进程优先级的设置可以参考以下原则：

**1）系统进程 > 用户进程**

**2）交互型进程 > 非交互型进程(前台进程 > 后台进程)**

**3）I/O型进程 > 计算型进程**



4. **高响应比优先调度算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-24,2011-23</font>

&emsp;&emsp;高响应比优先调度算法**用于作业调度**，**是对FCFS调度算法和SJF调度算法的一种综合平衡**，同时**还考虑了每个作业的等待时间和估计的运行时间**。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。

&emsp;&emsp;响应比的变化规律可描述为
$$
响应比R_p =\frac{等待时间+要求服务时间}{要求服务时间}
$$
**特点**：

1）作业的等待时间相同时，要求服务的时间越短，响应比越高，有利于短作业。

2）要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高。

3）对于长作业，作业的响应比可以随着等待时间的增加而提高，**克服了饥饿状态**。



5. **时间片轮转调度算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2014-23,2017-27</font>

&emsp;&emsp;时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按时间的先后顺序排成一个队列，进程调度程序选择就绪进程依次执行一个时间片。在执行的过程中，即使未完成运行，它也必须释放出处理机给下一个就绪进程。

**特点**：时间片的大小对系统的性能影响很大。

1）若时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。

2）若时间片很小，则处理机将在进程间过于频繁的切换，使处理机的开销增大，而真正用于进程的时间将减少。

- **时间片的大小由如下因素决定**

  **1）系统响应时间**	**2）就绪队列中的进程数目**	**3）系统的处理能力**

**【注】**时间片轮转调度算法不会导致饥饿现象



6. **多级反馈队列调度算法(综合了前几种算法的优点)**

&emsp;&emsp;多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合与发展。通过动态调整进程优先级和时间片大小，多级反馈队列可以兼顾多方面的系统目标。

<img src="./操作系统/2.2.5-3.png" alt="2.2.5-3" style="zoom:80%;" />

多级反馈队列算法的实现思想如下：

1）**设置多个就绪队列，并为每个队列赋予不同的优先级**，第1级队列的优先级最高，第2级队列次之，其余队列的优先级依次降低。

2）**赋予各个队列中进程执行时间片的大小各不同**。在**优先级越高的队列中，每个进程运行的时间片越小**。

3）一个新进程进入内存后，首先将它放在第1级队列的尾部，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可以撤离系统；若它不能在一个时间片内完成，调度程序将该进程转入第2级队列的尾部，按照和第1级队列的执行方式执行。.....依次进行下去。

4）仅当第1级队列为空时，调度程序才调度第2级队列中的进程运行；仅当第1~(i-1)级队列为空时，调度程序才调度第i级队列中的进程运行。若处理机正在执行第i级队列中的某进程时，这时又有新进程进入优先级较高的队列(即1~n-1中任一队列)，则此时心进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回第i级队列的末尾，把处理机分配给新到的更高优先级的进程。

**特点**：

**1）终端型作业用户**：短作业优先

**2）短批处理作业用户**：周转时间较短

**3）长批处理作业用户**：经过前面几个队列得到部分执行，不会长期得不到处理。



### 2.3 进程的同步

#### 2.3.1 进程同步的基本概念

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2011-32,2016-30</font>

1. **临界资源**

&emsp;&emsp;我们将**一次只允许一个进程使用的资源称为临界资源**。许多物理设备都属于临界资源，如打印机等。此外，还有许多变量、数据等都可以被若干进程共享，也属于临界资源。

&emsp;&emsp;在每个进程中，访问临界资源的那段代码称为临界区。为了保证临界资源的正确使用，可把临界资源的访问过程分为4个部分：

**1）进入区**：为了进入临界区使用临界资源，在进入区要检查可否进入临界区，若能进入临界区，则设置正在访问临界区标志，以阻止其他进程同时进入临界区。

**2）临界区**：进程中访问临界资源的那段代码，又称为临界段。

**3）退出区**：将正在访问临界区的标志清除。

**4）剩余区**：代码中的其余部分。

```c
do{
	entry section;		//进入区
    critical section;	//临界区
    exit section;		//退出区
    remainder sections; //剩余区
}
```

2. **同步**

&emsp;&emsp;同步亦称**直接制约关系**，是指为完成某任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程的直接制约关系源于它们之间的合作。

- **例子**

<img src="./操作系统/2.3.1-1.png" alt="2.3.1-1" style="zoom:80%;" />

3. **互斥**

&emsp;&emsp;互斥也称为**间接制约关系**。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界区资源的进程退出临界区后，另一个进程才允许去访问此临界资源。

- **例子**

<img src="./操作系统/2.3.1-2.png" alt="2.3.1-2" style="zoom:80%;" />

为了禁止两个进程同步进入临界区，**同步机制应该遵循以下准则**：

<img src="./操作系统/2.3.1-3.png" alt="2.3.1-3" style="zoom:80%;" />



#### 2.3.2 实现临界区互斥的基本方法

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2016-27</font>

1. **软件实现方法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-27</font>





#### 2.3.3 信号量

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-25</font>

<font color='#0099ff' size=5 face="黑体">大题：</font><font color='#FF0000' size=4 face="黑体">2009-45,2011-45,2013-45,2014-47,2015-45,2017-46</font>

&emsp;&emsp;信号量是一种功能较强的机制，可用来解决互斥与同步问题，它只能被两个标准原语wait(S)和signal(S)访问，也可记为“P操作”和“V操作”。

**【注】**原语是指完成某种功能且不被分割、不被中断执行的操作序列，通常可由硬件来实现。例如前述的Test-and-Set和Swap指令就是由硬件实现的原子操作。

1. **整型信号量**

&emsp;&emsp;整型信号量被定义为一个用于表示资源数目的整型量S，wait和signal操作可描述为：

```c
wait(S){
	while(S<=0);
	S = S - 1
}
signal(S){
    S = S + 1
}
```

&emsp;&emsp;wait操作中，只要信号量$S\le 0$，就会不断地测试。因此，**该机制并未遵循“让权等待”的准则，而是促进进程处于“忙等”状态**。

2. **记录型信号量**

&emsp;&emsp;记录型信号量是不存在“忙等”现象的进程同步机制。除需要一个用于代表资源数目的整型变量value外，再**增加一个进程链表L，用于链表所有等待该资源的进程**。记录型信号量得名于采用了记录型的数据结构，可描述为

```c
typedef sturct{
	int value;
	struct process *L;
}semaphore;
```

- **wait(S)的操作**

```c
void wait(semaphore S){ //相当于申请资源
	S.value--;
    if(S.value<0){ 		//表示资源已经分配完毕
        add this process to S.L;
        //采用block原语，进行自我阻塞，放弃处理机，并插入该类资源的等待队列S.L
        block(S.L);	
    }
}
```

- **signal(S)的操作**

```c
void signal(semaphore S){ //相当于释放资源
	S.value++;
    if(S.value<=0){		  //表示S.L中仍有等待资源的进程被阻塞
        remove a process P from S.L;
        wakeup(P)		 //调用wakeup原语将S.L中的第一个进程唤醒
    }
}
```

3. **利用信号量实现同步**

&emsp;&emsp;**设S为实现进程P1、P2同步的公共信号量，初值为0**。进程P2中的语句y要使用P1中语句x的运行结果，所以只有当语句x执行完成之后语句y才可以执行。其实现进程同步的算法如下：

```c
semaphore S = 0;	//初始化信号量
P1(){
	...
    x;				//语句x
    V(S);			//告诉进程P2，语句x已经完成
}
P2(){
    ...
    P(S);			//检查语句x是否运行完成
    y;				//检查无误，运行y语句
    ...
}
```

4. **利用信号量实现进程互斥**

&emsp;&emsp;设S为实现进程P1、P2互斥的信号量，由于每次只允许一个进程进入临界区，所以S的初值应为1(可用资源应数为1)。只需把临界区置于P(S)和V(S)之间，即可实现两个进程对临界资源的互斥访问。其算法如下：

```c
semaphore S = 1;		//初始化信号量
P1(){
    ...
    P(S);				//准备开始访问临界资源，加锁
    进程P1的临界区;
    V(S);				//访问结束，解锁
    ...
}
P2(){
    ...
    P(S);				//准备开始访问临界资源，加锁
    进程P2的临界区；	   
    V(S);				//访问结束，加锁
    ...
}
```



#### 2.3.4 管程

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2014-31,2016-32</font>

1. **管程的定义**

&emsp;&emsp;系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。**管程是由一组数据及定义在这组数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程**。

2. **管程的组成**

1）局部于管程的共享结构数据说明

2）对该数据结构进行操作的一组过程

3）对局部于管程的共享数据设置初始的语句

3. **管程的基本特性**

1）局部于管程的数据只能被局部于管程内的过程所访问

2）一个进程只能通过调用管程内的过程才能进入管程访问的共享数据

3）每次仅允许一个进程在管程内执行某个内部过程

由于管程是一个语言成分，因此管程的互斥访问完全由编译程序在编译时自动添加无须程序员关注，而且保证正确。



### 2.4 死锁

#### 2.4.1 死锁的概念

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-25,2014-24</font>

1. **死锁的定义**

&emsp;&emsp;多道程序的并发执行会带来死锁现象，这是指多个进程因竞争资源而造成的一种僵局(相互等待)，若无外力作用，这些进程都将无法向前推进。

2. **死锁产生的原因**

**（1）系统资源的竞争**

&emsp;&emsp;通常系统中拥有不可剥夺资源，其数量不足以满足多个进程运行的需求，使得进程在运行时陷入僵局，如磁带机、打印机等。**只有对不可剥夺资源的竞争才可能产生死锁，对于可剥夺资源的竞争是不会产生死锁的**。

**（2）进程推进顺序非法**

**（3）死锁产生的必要条件**

产生死锁必须同时满足以下4个条件，只要其中任意一个条件不成立，死锁就不会发生。

- **互斥条件**：即在一段时间内某资源仅为一个进程所占有，其它请求进程只能等待。
- **不剥夺条件**：进程获得的资源在未使用完之前，不能被其它进程强行夺走，只能是主动释放。
- **请求并保持等待**：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。
- **循环等待条件**：存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被下一个进程所请求。

**【注】**破坏循环等待条件，一般采用顺序请求资源分配法。



#### 2.4.2 死锁的处理策略

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2015-26</font>

1. **死锁预防**

设置某些限制条件，破坏产生死锁的4个必要条件中的一个或几个，以防止产生死锁。

2. **避免死锁**

在资源的动态分配过程中，用某种方法**防止系统进入不安全状态**，从而避免死锁。

3. **死锁的检测及解除**

&emsp;&emsp;无须采取任何限制性措施，允许在运行过程中发生死锁。通过系统检查出死锁的发生，然后采取某种措施解除死锁。

<img src="./操作系统/2.4.2-1.png" alt="2.4.2-1" style="zoom:85%;" />



#### 2.4.4 死锁避免

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2011-27,2012-27,2013-32</font>

1. **系统安全状态**

&emsp;&emsp;避免死锁的方法中，允许死锁动态地申请资源，但系统在进行资源分配之前，应先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则让进程等待。

&emsp;&emsp;所谓的安全状态，是指系统能按某种进程推进顺序$(P_1,P_2,\dots,P_n)$为每个进程$P_i$分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可以顺序完成，此时$P_1,P_2,\dots,P_n$为**安全序列**。若系统无法找到一个安全序列，则称系统处于不安全状态。

- **例子**

<img src="./操作系统/2.4.4-1.png" alt="2.4.4-1" style="zoom:80%;" />

安全序列：$P_2,P_1,P_3$。

**【注】**：并非所有的不安全状态都是死锁状态，但系统进入不安全状态后，便可能进入死锁状态；反之，只要系统处于安全状态，系统便可避免进入死锁状态。

2. **银行家算法**

**（1）数据结构描述**

- **可利用资源向量Available**：含有$m$个元素的数组，其中每个元素代表一类可用的资源数目，Available[j] = K表示系统中现有$R_j$类资源$K$个。
- **最大需求矩阵Max**：$n \times m$ 矩阵，定义系统中$n$个进程中每个进程对m类资源的最大需求。简单来说，一行代表一个进程，一列代表一类资源。$Max[i,j]=K$表示进程$i$需要$R_j$类资源的最大数目为$K$。
- **分配矩阵Allocation**：$n \times m$ 矩阵，定义系统中每类资源当前已分配给每个进程的资源数。$Allocation[i,j]=K$表示进程$i$当前已分得$R_j$类资源的数目为$K$。
- **需求矩阵Need**：$n \times m$矩阵，表示每个进程尚需的各类资源数。$Need[i,j]=K$表示进程$i$还需要$R_j$类子元素数目为$K$。

- 上述矩阵间存在如下关系

$$
Need=Max-Allocation
$$

**（2）银行家算法描述**

&emsp;&emsp;设$Request_i$是进程$P_i$的请求向量，$Request_i[j]=K$表示进程$P_i$需要$R_j$类资源$K$个。当$P_i$发出资源请求后，系统按下述步骤进行检查：

① 若$Request_i[j] \le Nedd[i,j]$，则转向步骤②；否则认为出错，因为它所需的资源数已超过它所宣布的最大值。

② 若$Request_i[j] \le Available[j]$，则转向步骤③；否则，表示无足够资源，$P_i$需等待。

③ 系统试探着把资源分配给进程$P_i$，并修改下面数据结构的数字
$$
\begin{aligned}
& Available = Available - Request_i; \\
& Allocation[i,j] = Allocation[i,j]+Request_i[j] \\
& Need[i,j] = Need[i,j] - Request_i[j]
\end{aligned}
$$
④ 系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式将资源分配给进程$P_i$，以完成本次分配；否则，将本次的试探分配作废，恢复原理的资源分配状态，让进程$P_i$等待。

**（3）安全性算法**

<img src="./操作系统/2.4.4-2.png" alt="2.4.4-2" style="zoom:80%;" />

3. **安全性算法例子**

&emsp;&emsp;假定系统中有5个进程$\{P_0,P_1,P_2,P_3,P_4\}$和三类资源$\{A,B,C\}$，各种资源的数量分别为10、5、7，在$T_0$时刻的资源分配情况见表

<img src="./操作系统/2.4.4-3.png" alt="2.4.4-3" style="zoom:80%;" />

<img src="./操作系统/2.4.4-4.png" alt="2.4.4-4" style="zoom:80%;" />

<img src="./操作系统/2.4.4-5.png" alt="2.4.4-5" style="zoom:80%;" />





## 第3章 内存管理

### 3.1 内存管理概念

#### 3.1.1 内存管理的基本原理和要求

<font color='#0099ff' size=5 face="黑体">考点：</font><font color='#FF0000' size=4 face="黑体">2009-26,2011-30</font>

1. **内存管理的功能**

**1）内存空间的分配与回收**：由操作系统完成主存储器空间的分配与管理。

**2）地址转换**：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储器管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。

**3）内存空间的扩充**：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。

**4）存储保护**：保证各道作业在各自的存储空间内运行，互不干扰。

2. **程序的装入和链接**

创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：

- **编译**：由编译程序将用户源代码编译成若干目标模块，这一过程会形成**逻辑地址**。

- **链接**：由链接程序将编译后形成的一组目标模块及所需要的库函数链接在一起，形成一个完整的装入模块。链接有以下三种方式

​	**（1）静态链接**：在程序运行前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。

​	**（2）装入时动态链接**：将用户程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的方式。

​	**（3）运行时动态链接**：对某些目标模块的链接，是在程序执行中需要该目标模块时才进行的。其优点是便于修改与更新，便于实现对目标模块的共享。

- **装入**

**（1）绝对装入**：逻辑地址和物理地址完全相同。

**特点**：只适用于单道程序环境，程序所用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。**通常情况下程序采用的是符号地址**，编译或链接时再转为绝对地址。

**（2）可重定位装入(静态重定位)**：通常在多道程序中，根据内存的情况，将装入模块装入内存适当的位置。装入时对指令和数据的修改过程称为重定位，地址变化通常是在装入时一次完成，所以又称为静态重定位。

**特点**：一个作业装入内存时，必须给它分配全部的内存空间，整个运行期间就不能在内存中移动，也不能再申请内存空间。

**（3）动态运行时装入(动态重定位)**：装入程序把装入模块装入内存后，并不立即把模块中的相对地址转换为绝对地址，而是把这种地址的转换推迟到真正要执行时才进行。

**特点**：可以将程序分配到不连续的存储区，在程序运行之前可以只装入它的部分代码即可投入运行。

<img src="./操作系统/3.1.1-1.png" alt="3.1.1-1" style="zoom:80%;" />





#### 3.1.3 连续分配管理方式

&emsp;&emsp;连续分配方式是指为一个用户程序分配一个连续的内存空间。

1. **单一连续分配(单道)**

&emsp;&emsp;内存在此方式下分为系统区和用户区，系统区仅供操作系统使用，通常在低地址部分；用户区还是用户提供的、除系统区之外的内存空间。**这种方式无须进行内存保护，因为在内存中永远只有一道程序，因此肯定不会因为访问越界而干扰其他程序**。

2. **固定分区分配(多道)**

&emsp;&emsp;内存在此方式下划分为若干固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可以从外存的后备作业队列中选择适当大小的作业装入该分区，如此循环。

![3.1.3-1](./操作系统/3.1.3-1.png)

&emsp;&emsp;为了便于内存分配，通常将分区大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的起始地址、大小及状态(是否已分配)。

![3.1.3-2](./操作系统/3.1.3-2.png)

3. **动态分区分配(多道)**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-28,2017-25</font>

&emsp;&emsp;动态分区分配又称可变分区分配，是一种动态划分内存的方法。这种分区方法不预先划分内存，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好合适进程的需要。因此，系统中分区的大小和数目是可变的。

![3.1.3-3](./操作系统/3.1.3-3.png)

&emsp;&emsp;动态分区的分配策略：

​		**1）首次适应(First Fit)算法**：空闲分区**按地址递增**的次序链接。分配内存时顺序查找，找到大		小能满足要求的第一个空闲分区。

​		**2）最佳适应(Best Fit)算法**：空闲区**按容量递增**的方式形成分区链，找到第一个能满足要求的空		闲分区。

​		**3）最坏适应(Worst Fit)算法**：又称最大适应(Largest Fit)算法，空闲分区**按容量递减**的次序链   		接。找到第一个能满足要求的空闲分区，即挑选出最大的分区。

​		**4）邻近适应(Next Fit)算法**：又称循环首次适应算法，由首次适应算法演变而成。不同之处是，分配内存时**从上一次查找结束的位置开始继续查找**。

**【注】**以上3种内存分区管理方式对比

![3.1.3-4](./操作系统/3.1.3-4.png)



#### 3.1.4 非连续分配管理方式

&emsp;&emsp;非连续分配允许一个程序分散地装入不相邻的内存分区。

##### 1. 基本分页式管理方式

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-29,2011-28,2014-28</font>

<font color='#0099ff' size=5 face="黑体">大题：</font><font color='#FF0000' size=4 face="黑体">2009-46[重],2013-46[重],2015-46</font>

&emsp;&emsp;把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

&emsp;&emsp;分页管理不会产生外部碎片，进程只有在为最后一个不完整块申请一个主存空间时，才产生内部碎片(也称为页内碎片)。

**（1）分页存储的几个概念**

- **页面和页面大小**

&emsp;&emsp;**进程中的块称为页(Page)，内存中的块称为页框(Page Frame，或页帧)**。外存也以同样的单位进行划分，直接称为块(Block)。进程在执行时需要申请主存空间，即为每个页面分配主存中的可用页框。

&emsp;&emsp;页面大小应该是2的整数幂。页面太小会使进程的页面过多，页表过长，占用大量的内存，增加硬件地址转换的开销，降低页面换人/换出的效率；页面过大会使内部碎片增多，降低内存利用率。

- **地址结构**

&emsp;&emsp;分页存储管理的逻辑地址结构如图

<img src="./操作系统/3.1.4-1.png" alt="3.1.4-1" style="zoom:80%;" />

① 0~11位为页内地址，即每页大小为$2^{12}B=4KB$

② 12~31位为页号，地址空间最多允许$2^{20}$页

- **页表**

&emsp;&emsp;为了便于内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，它记录页面在内存中对应的物理块号，**页表一般存放在内存中**。

&emsp;&emsp;页表由页表项组成，**页表项 = 页号 + 页框号**。

**&emsp;&emsp;物理地址 = 页内地址 + 页框号 &times; 页面大小**

<img src="./操作系统/3.1.4-2.png" alt="3.1.4-2" style="zoom:80%;" />

**（2）基本地址变换机构**

&emsp;&emsp;地址变换机构的任务是将逻辑地址转换为内存中的物理地址，地址变换是借助于页表实现的。

<img src="./操作系统/3.1.4-3.png" alt="3.1.4-3" style="zoom:80%;" />

- **页表寄存器(PTR)**

&emsp;&emsp;存放页表在内存的**起始地址F**和**页表长度M**。**进程未执行时，页表的起始地址和长度放在程序控制块中，当进程执行时，才将页表始址和长度存入页表寄存器**。

- **地址变换机制**

&emsp;&emsp;设页面大小为$L$，逻辑地址$A$到物理地址$E$的变换过程如下(逻辑地址、页号、每页的长度都是十进制)

① 计算页号$P(P=A/L)$和页内偏移量$W(W=A\%L)$

② 比较页号$P$和页表长度$M$，若$P \ge M$，则产生越界中断，否则继续执行

③ 页表中页号$P$对应的**页表项地址 = 页表起始$F$ + 页号$P$&times;页表项长度**，取出该页表项内容$b$，即物理块号(页框号)。

**【注】页表长度的值是指一共有多少页，页表项长度是指页地址占多大的存储空间。**

④ 计算$E = b\times L +W$，用得到的物理地址$E$去访存。

- **例子**

<img src="./操作系统/3.1.4-4.png" alt="3.1.4-4" style="zoom:80%;" />

- **如何确定页表项的大小**

<img src="./操作系统/3.1.4-5.png" alt="3.1.4-5" style="zoom:80%;" />

**（3）分页式管理方式存在的问题**

① 每次访存操作都要进行逻辑地址到物理地址的转换，这个转换过程必须要快，否则访存速度会降低。

② 每个进程引入页表，用于存储映射机制，页表不能太大，否则内存利用率会减低。

**（4）具有快表的地址变换机制**

&emsp;&emsp;若页表全部都放在内存中，则存取一个数据或者一条指令要**访问两次内存**。第一次是访问页表，第二次是取数据或指令。

&emsp;&emsp;**快表**又称为**相联存储器(TLB)**是一个具有并行查找能力的**高速缓冲存储器**，用来存放当前访问的若干表项，以加速地址变换过程。与此对应，**主存中的页表常称为慢表**。

<img src="./操作系统/3.1.4-6.png" alt="3.1.4-5" style="zoom:80%;" />

- **地址变换机制**

① CPU给出逻辑地址后，由硬件进行地址转换，将页号送人高速缓存寄存器，并将此页号与快表中的所有页号进行比较。

② 若找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样存储数据一次访存便可实现。

③ 若未找到，则需要访问主存中的页表，**在读出页表项后，应同时将其存入快表**，以便后面可能再次访问。但若快表已满，则必须按照一定的算法对旧的页表进行替换。

**【注】快表的有效性基于局部性原理**

**（5）两级页表**

<font color='#0099ff' size=5 face="黑体">考点：</font><font color='#FF0000' size=4 face="黑体">2014-32</font>

<img src="./操作系统/3.1.4-7.png" alt="3.1.4-5" style="zoom:80%;" />

【注】多级页表可以减少页表所占的连续空间



##### 2. 基本分段存储管理方式

<font color='#0099ff' size=5 face="黑体">考点：</font><font color='#FF0000' size=4 face="黑体">2009-27,2016-28</font>

&emsp;&emsp;分段管理方式的提出则考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需求。

- **分段**

&emsp;&emsp;段式管理按照用户进程中的自然段划分逻辑空间。

>  例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为5段，每段从0开始编制，并分配一段连续的地址空间(**段内连续，段间可以不连续**)。

<img src="./操作系统/3.1.4-8.png" alt="3.1.4-5" style="zoom:80%;" />

① 段号$S$为16，因此一个作业最多有$2^{16}=65536$段。

② 偏移量$W$为16位，故最大段长为64KB。

**【注】**在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显示提供，在高级程序设计语言中，这个工作由编译程序完成。

- **段表**

&emsp;&emsp;每个进程都有一张逻辑空间与内存空间映射的段表，**其中每个段表对应进程的一段**，**段表项记录该段在内存的始址和长度**。

<img src="./操作系统/3.1.4-9.png" alt="3.1.4-5" style="zoom:80%;" />



<img src="./操作系统/3.1.4-10.png" alt="3.1.4-5" style="zoom:80%;" />

- **地址变换机制**

&emsp;&emsp;在系统中设置了段表寄存器，用于存放段表始址$F$和段表长度$M$。从逻辑地址$A$到物理地址$E$之间的地址变换过程如下：

<img src="./操作系统/3.1.4-11.png" alt="3.1.4-5" style="zoom:80%;" />

① 从逻辑地址$A$中取出前几位为段号$S$，后几位为段内偏移量$W$。

**【注】**段式存储管理的题目中，逻辑地址一般以二进制数给出，而在页式存储管理中，逻辑地址以十进制数给出。

② 比较段号$S$和段表长度$M$，若$S \ge M$，则产生越界中断，否则继续执行。

③ **段表中段号$S$对应的段表地址 = 段表始址$F$ + 段号$S$ &times; 段表项长度**，取出该段表项的前几位得到段长$C$，若段内偏移量 $\ge C$，则产生越界中断，否则继续执行。

④ 取出段表项中的始址$b$，计算$E = b + W$，用得到的物理地址$E$去访存。

- **段的共享和保护**

**① 共享**

&emsp;&emsp;分段系统中，段的共享通过两个作业的段表中相应表项指向被共享段的同一物理副本来实现。

&emsp;&emsp;不可修改的代码称为**纯代码**或**可重入代码(它不属于临界资源)**，这样的代码和不能修改的数据可以共享，而修改的代码和数据不能共享。

**② 保护**

​	**1）存取控制保护**	**2）地址越界保护**

**【注】**分段管理的地址空间是二维的



### 3.2 虚拟内存管理

<font color='#0099ff' size=5 face="黑体">大题：</font><font color='#FF0000' size=4 face="黑体">2017-45</font>

#### 3.2.1 虚拟内存的基本概念

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2012-25</font>

1. **传统存储管理方式的特征**

**1）一次性**：作业必须一次性全部装入内存后，才开始运行。这会导致两种情况：**① 作业很大而不能全部装入内存时，将使该作业无法运行**；**② 当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降**。

**2）驻留性**：作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业结束运行为止。运行中的进程会因为等待I/O而被阻塞，可能长期处于等待状态。



2. **局部性原则**

**1）时间局部性**：程序中的某条指令一旦执行，不久后该指令可能再次执行；某数据被访问过，不久后该数据可能再次被访问，**产生时间局部性的典型原因是程序中存在着大量的循环操作**。

**2）空间局部性**：一旦程序访问了某个存储单元，不久后，其附近的存储单元也被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，因为**指令通常是顺序存放、顺序存储的，数据也一般是以向量、数组、表等形式簇聚存储的**。



3. **虚拟存储器的主要特性**

1）**多次性**：指无须在作业运行时一次性地全部装入内存，而允许被分为多次调入内部运行。

2）**对换性**：指无须在作业运行时一直常驻内存，而允许在作业运行过程中，进行换入和换出。

3）**虚拟性**：指从逻辑上扩充内存的容量，使用户看到的内存容量远大于实际的内存容量。



4. **虚拟存储技术的实现**

&emsp;&emsp;虚拟存储系统**只能基于非连续分配技术**，连续分配方式时，会使相当一部分内存空间处于暂时或者“永久”空闲的状态，严重造成内存资源的浪费。

1）请求分页存储管理

2）请求分段存储管理

3）请求段页式存储管理

不管哪种方式，都需要一定的**硬件的支持**，一般需要的支持有以下几个方面：

- 一定容量的**内存**和**外存**
- **页表机制(或段表机制)**，作为主要的数据结构
- **中断机制**，当用户程序要访问的部分尚未调入内存时，则产生中断
- **地址变换机制**，逻辑地址和物理地址的转换。







#### 3.2.3 页面置换算法

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2013-30</font>

<font color='#0099ff' size=5 face="黑体">大题：</font><font color='#FF0000' size=4 face="黑体">2010-46</font>

&emsp;&emsp;进程运行时，若其访问的页面不在内存中而需将其调入，但内存无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。

&emsp;&emsp;选择调出页面的算法就称为**页面置换算法**。

1. **最佳(OPT)置换算法**

&emsp;&emsp;最佳置换算法算账的被淘汰页是以后永久不使用的页面，或者在最长时间内不再被访问的页面，以便保证获得最低的缺页率。然而，**由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因此该算法无法实现**。

&emsp;&emsp;**最佳置换算法可用来评价其他算法**。假定系统为某进程分配了三个物理块，并考虑有页面号引入串7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1。最佳置换算法算法的过程如下

<img src="./操作系统/3.2.3-1.png" alt="3.2.3-1" style="zoom:80%;" />

缺页率：9

页面置换的次数：6



2. **先进先出(FIFO)页面置换算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2014-30</font>

&emsp;&emsp;**优先淘汰最早进入内存的页面，即在内存中驻留时间最久的页面**。该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总是指向最早的页面。但该算法与进程实际运行时规律不适应，因为在进程中，有的页面经常被访问。例子仍然是上述的例子

<img src="./操作系统/3.2.3-2.png" alt="3.2.3-2" style="zoom:80%;" />

&emsp;&emsp;FIFO算法还会**产生分配的物理块数增大而页面故障数不减的反增的异常现象**，称为**Belady异常**。**只有FIFO算法可能出现Belady异常，LRU和OPT算法永远不会出现Belady异常**。

&emsp;&emsp;如图所示，页面访问的顺序为3,2,1,0,3,2,4,3,2,1,0,4。若采用FIFC置换算法，当分配的物理块为3个时，缺页次数为9次；当分配的物理块为4个时，缺页次数为10次。分配给进程的物理块增多，但缺页次数不减反增。

<img src="./操作系统/3.2.3-3.png" alt="3.2.3-3" style="zoom:80%;" />

3. **最近最久未使用(LRU)置换算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2015-27</font>

&emsp;&emsp;选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近将来可能也不会被访问。**该算法为每个页面设置一个访问字段，来记录页面自上一次被访问以来经历的时间，淘汰页面时选择现有页面中值最大的淘汰**。还是之前的例子：

<img src="./操作系统/3.2.3-4.png" alt="3.2.3-4" style="zoom:80%;" />

&emsp;&emsp;LRU的算法性能较好，但**需要寄存器和栈的硬件支持**。LRU是堆栈类算法，FIFO是基于队列实现的。



4. **时钟(CLOCK)置换算法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2016-26</font>

&emsp;&emsp;简单的CLOCK算法给每帧关联一个附加位，称为**使用位**。当某页首次装入主存时，将该帧的使用位置为1。对于页替换算法，用于替换的候选帧集合可以视为一个**循环缓冲区**，并有一个指针与之相关联。

&emsp;&emsp;当某一页被替换时，将使用位置1，并将该指针指向下一帧。当需要替换一页时，操作系统扫描缓冲区，以便找使用位为0的帧。每当遇到一个使用位为1的帧，操作系统将该位重新置为0；若在这个过程开始时，缓冲区中所有的帧使用位为0，则选择遇到的第一个帧替换；若所有帧的使用位均为1，则指针在缓冲区中完整的循环一遍，把所有使用位都置为0，并停留在最初的位置上，替换该帧中的页。

&emsp;&emsp;CLOCK又称**最近未用(Not Recently Used, NRU)算法**。

- **改进型CLOCK算法**

每帧都处于以下4种情况之一：

1）最近未被访问，也未被修改(u = 0, m = 0)

2）最近被访问，但未被修改(u = 1, m = 0)

3）最近未被访问，但被修改(u = 0, m = 1)

4）最近被访问，被修改(u = 1, m = 1)

**算法流程：**

（1）从指针的当前位置开始，扫描帧缓冲区，在这次扫描过程中，对使用位不做任何修改，选择遇到的第一个帧(u = 0, m = 0)用于替换。

（2）若第（1）步失败，则重新扫描，查找(u = 0, m = 1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对于每个跳过的帧，将它的使用位置成0。

（3）若第（2）步失败，则指针将回到它最初位置，且集合所有帧的使用位均为0，重复第（1) 步，并且有必要，重复第（2）步，以便可以找到供替换的帧。



#### 3.2.4 页面分配策略

1. **驻留集大小**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2015-30</font>

&emsp;&emsp;对于分页式的虚拟内存，在进程准备执行时，不需要也不可能把一个进程的所有页读入内存。因此，操作系统必须决定读多少页，即决定给特定的进程分配几个页框。**给一个进程分配的物理页框的集合就是这个进程的驻留集**。需要考虑如下几点：

1）分配给一个进程的存储量越小，任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用率。

2）若一个进程在主存中的页数过少，则尽管有局部性原理，页错误率仍然会相对较高。

3）若页数过多，则由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有显著的影响。

基于这些因数，现代操作系统通常采用三种策略：

<img src="./操作系统/3.2.4-1.png" alt="3.2.4-1" style="zoom:80%;" />



#### 3.2.5 抖动

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2011-29</font>

- **定义**

&emsp;&emsp;在页面置换算法中，**刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存**，这种频繁的页面调度行为称为**抖动或颠婆**。

- **发生抖动的原因**

&emsp;&emsp;某个进程频繁访问页面数目高于可用的物理页面帧数目。虚拟内存技术可在内存中保留更多的进程以提高系统效率。在稳定状态，几乎主存的所有空间都被进程占据，处理机和操作系统可以直接访问到尽可能多的进程。然而，如果管理不当，那么处理机大部分的时间都用于交换块，即请求调入页面的操作，而不是执行进程的指令，因此大大降低系统的效率。

**【注】**：当系统发生抖动时，可以采取的措施是撤销部分进程。



#### 3.2.6 工作集

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2016-29</font>

&emsp;&emsp;工作集是指在某段时间间隔内，进程要访问的页面集合。**基于局部性原理**，可以用最近访问过的页面来确定工作集。一般来说，工作集$W$可由时间$t$和工作集窗口大小$\Delta$来确定，例如，某进程对页面的访问次序如下：

![3.2.6-1](./操作系统/3.2.6-1.png)

&emsp;&emsp;假设系统为该进程设定的工作集窗口大小$\Delta$为5，则在$t_1$时刻，进程的工作集为{2,3,5}，在$t_2$时刻，进程的工作集为{1,2,3,4}。

&emsp;&emsp;工作集反映了进程在接下来的一段时间内很有可能频繁访问的页面集合，若分配给进程的物理块小于工作集的大小，则该进程就很可能频繁缺页，所以为了防止这种抖动现象，一般来说分配给进程的**物理块(驻留集)要大于工作集的大小**。

- **工作集模型的原理**

<img src="./操作系统/3.2.6-2.png" alt="3.2.6-2" style="zoom:80%;" />



## 第4章 文件系统

### 4.1 文件系统基础

#### 4.1.1 文件的概念

##### 1. 文件的定义

自底向上定义文件：

<img src="./操作系统/4.1.1-4.png" alt="4.1.1-4" style="zoom:85%;" />

##### 2. 文件的属性

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2013-26,2017-26</font>

<img src="./操作系统/4.1.1-3.png" alt="4.1.1-3" style="zoom:85%;" />

&emsp;&emsp;**所有文件的信息都保存在目录结构中，而目录结构保存在外存上。**文件信息在需要时才会调入内存。通常，**目录条目包括文件名称及其唯一的标识符(索引结点iNode)**，而**标识符定位其它属性的信息**。

**【注】**一个文件通常是存放在一个或多个簇里的

- **单级文件大小长度有关的因素**

1）间接地址索引的级数

2）地址项的个数

3）文件块的大小



##### 3. 文件的基本操作



- **读文件**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2012-28</font>

&emsp; &emsp;读文件会调用一个 **read系统调用**，read系统调用要求用户提供三个参数：**① 文件描述符fd	② buf缓冲区首址	③ 传送的字节数n**，它的功能是试图从fd所指示的文件中读入n个字节的数据，并将它们送至由指针buf所指示的缓冲区中。read系统调用有如下特点：

1）当所读文件的数据不在内存时，产生中断(缺页中断、缺段中断)，原进程进入阻塞状态(睡眠等待状态)，直到所需的数据从外存调入内存后，将该进程唤醒，使其变成就绪态。

2）read系统调用通过**陷入**将CPU从用户态切换到核心态，从而获取操作系统提供的服务。

3）read系统调用参数需要open返回的文件描述符。



- **删除文件**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2013-23</font>

&emsp;&emsp;先从目录中找到删除文件的**目录项**，使之成为空项，然后再回收该文件**所占用的存储空间**，以及**与此文件对应的文件控制块**。





##### 4. 文件的打开与关闭

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2014-29</font>

&emsp;&emsp;许多系统首次使用文件时，使用**系统调用open**将指明**文件的属性(包括该文件在外存上的物理位置)**从外存复制到内存打开文件表的一个表目中**(将文件的控制块读到内存)**，并将该表目的编号(索引)返回给用户。操作系统维持一个包含所有打开文件信息的表(**打开文件表，open-file table**)。当用户需要一个文件操作时，可通过该表的一个索引指定文件；当文件不再使用时，操作系统从打开文件表中删除这一条目。

- **open系统调用需要的参数与返回参数**

**1）需要的参数**：文件路径和文件名

**2）返回参数**：指向文件表中一个条目的指针

- **文件打开计数器(Open Count)**

&emsp;&emsp;通常，系统打开一个文件时，还用一个文件打开计数器，以**记录多少进程打开了该文件**。每个关闭操作close使count递减，当打开计数器为0时，表示该文件不再被使用，系统调用将回收分配给该文件的内存空间等资源。**若文件被修改，则将文件写回外存**，并将系统打开文件表中的相应条目删除，最后**释放文件的文件控制块(File Control Clock，FCB)**。

- **每个打开文件关联的信息**

<img src="./操作系统/4.1.1-1.png" alt="4.1.1-1" style="zoom:80%;" />

<img src="./操作系统/4.1.1-2.png" alt="4.1.1-2" style="zoom:80%;" />





#### 4.1.2 文件的逻辑结构

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-30</font>

1. **无结构文件(流式文件)**

&emsp;&emsp;以**字节**为单位，由于无结构文件没有结构，因而对记录的访问只能通过**穷举搜索**的方式。那些对基本信息单位操作不多的文件适于采用字符流的无结构方式，如**源程序文件**、**目标代码文件**等。

2. **有结构文件(记录式文件)**

   **1）顺序文件：**文件记录顺序排列，记录通常是定长的，可以**顺序存储**或**链表形式存储**。在对记录进行批量操作时，即每次要读或者写一大批记录时，顺序文件的效率是所有逻辑文件中最高的。但顺序文件对查找、增加或删除单条记录的操作比较困难。

   **2）索引文件：**支持可变长记录的**随机访问**。

   **3）索引顺序文件：**是顺序文件和索引文件两种组织形式的结合。

   **4）直接文件或散列文件**



#### 4.1.3 目录结构

&emsp;&emsp;与文件管理系统和文件集合相关联的是文件目录，它包含文件的信息如属性、位置和所有权等，这些信息主要由操作系统进行管理。

1. **文件控制块和索引结点**

   <font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-30</font>

   **1）文件控制块(FCB)：**用来存放控制文件所需的各种信息的数据结构，以实现“**按名存取**”。FCB的有序集合称为文件目录，一个FCB就是一个文件目录项。

   **2）索引结点：**$文件目录项=文件名+索引结点$

2. **目录结构**

   <font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-31</font>
   
   **1）单级目录结构：**在整个文件系统中只建立一张目录表，每个文件占一个目录项。

![4.1-1](./操作系统/4.1-1.png)

​		**缺点：**查找速度慢，不允许重名，不便于文件共享。

​		**2）两级目录结构：**解决了重名问题，但是缺乏灵活性，但不利于文件分类。

![4.1-2](./操作系统/4.1-2.png)

​		**3）多级目录结构(树形目录结构)：**将两级目录结构的层次关系加以推广，就形成了多级目录结构。能有效的进行文件的管理和保护，但是会增加磁盘的访问次数。易于实现文件分类，但不便于实现文件共享。

![4.1-3](./操作系统/4.1-3.png)

- **绝对路径**：从根目录出发的路径，如/dev/hda

- **相对路径：**从当前目录出发，可用cd命令改变当前目录，如 ./ls，其中符号“.”表示当前目录

  **4）无环图目录结构：**实现了文件共享，需要在共享结点处设置一个共享计数器，每当图中增加对该结点的共享链时，计数器加1；每当有用户提出删除该结点时，计数器减1。仅当计数器为0时，才真正删除该结点，否则仅删除请求用户的共享链。

![4.1-4](./操作系统/4.1-4.png)

#### 4.14 文件共享

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-31,2017-31</font>

1. **基于索引结点的共享方式(硬连接)**

![4.1-5](./操作系统/4.1-5.png)



![4.1-6](./操作系统/4.1-6.png)

2. **基于符号链实现文件共享(软链接)**

&emsp;&emsp;只有文件的拥有者才拥有指向其索引结点的指针。而共享文件的其它用户只有**该文件的路径名**，不拥有指向其索引结点的指针。



#### 4.1.5 文件的保护

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2017-30</font>

&emsp;&emsp;为了防止文件共享可能会导致文件被破坏或未经批准用户修改文件，文件系统必须控制用户对文件的存取，即解决对文件的读、写、执行的许可问题。为此，必须在文件系统中建立相应的文件保护机制。

&emsp;&emsp;文件保护通过**口令保护**、**加密保护**和**访问控制**等方式实现。其中，**口令保护和加密保护是为了防止用户文件被他人存取或窃取**，而访**问控制则用于控制用户对文件的访问方式**。

1. **访问类型**

<img src="./操作系统/4.1.5-1.png" alt="4.1.5-1" style="zoom:80%;" />

此外还有重命名、复制、编辑等加以控制。**这些高层的功能可以通过系统程序调用低层系统调用来实现**。**保护可以只在低层提供**。

2. **访问控制**

&emsp;&emsp;解决访问控制最常用的方法是**根据用户身份进行控制**。而实现基于身份访问的最为普通的办法是，为每个文件和目录增加一个**访问控制列表(Access-Control List,ACL)**，以规定每个用户名及其所允许的访问类型。

&emsp;&emsp;访问列表通常有三种类型：

​	**1）拥有者**：创建文件的用户

​	**2）组**：一组需要共享文件其具有类似访问的用户

​	**3）其他**：系统内的所有其他用户。

- **口令**

&emsp;&emsp;口令是指**用户在建立一个文件时提供一个口令，系统为其建立FCB时附上相应的口令，同时告诉允许共享该文件的其他用户**。用户请求访问时必须提供相应的口令。这种方法**时间和空间开销不多，缺点是口令直接在系统内部，不够安全**。

- **密码**

&emsp;&emsp;密码指用户对文件进行加密，文件被访问时需要使用密钥。**这种方法保密性强，节省了存储空间，不过编码和译码都要花上一段时间**。

**【注】**口令和密码都是防止用户文件被他人存取或窃取，并没有控制用户对文件的访问类型。

- **注意的两个问题**

<img src="./操作系统/4.1.5-2.png" alt="4.1.5-2" style="zoom:80%;" />



### 4.2 文件系统的实现



#### 4.2.3 文件实现(物理结构)

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-30</font>

<font color='#0099ff' size=5 face="黑体">大题：</font><font color='#FF0000' size=4 face="黑体">2011-46,2012-46[重],2014-46[重],2016-47[重]</font>

文件的实现就是研究文件的**物理结构**，即文件数据存储在物理存储设备上是如何分布和组织的。

##### 1. 文件分配方式

文件发分配对应于文件的物理结构，是指如何为文件分配磁盘块。

**（1）连续分配**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2013-24</font>

&emsp;&emsp;连续分配方法要求每个文件在磁盘块上占有一组连续的块。磁盘地址定义了磁盘上的一个线性排序，这种排序使作业**访问磁盘时需要的寻道数和寻道时间最小**。**会产生外部碎片**。

<img src="./操作系统/4.2.3-1.png" alt="4.2.3-1" style="zoom:90%;" />

**（2）链接分配**

- **隐式链接**：每个文件对应一个**磁盘块链表**；磁盘块分布在磁盘的任何地方，除最后一个盘块外，每个盘块都有指向下一个盘块的指针，这些指针对于用户是透明的。**目录包括文件第一块的指针和最后一块的指针**。

<img src="./操作系统/4.2.3-2.png" alt="4.2.3-2" style="zoom:90%;" />

- **显示链接**：把用于链接文件各物理块的指针，从每个物理块的末尾中提取出来，显示地存放在内存的一张**链接表**中。每个表项中存放对应块的下一块指针，即下一个盘块号。例如在隐式链接分配中对应的链接表为：

  | 盘块号 | 内容 |
  | ------ | ---- |
  | 1      | 10   |
  | ...    | ...  |
  | 10     | 25   |
  | ...    | ...  |

  由于分配给该文件的所有盘块号都放在了该表，故称该表为**文件分配表（File Allocation Table，FAT）**。

**（3）索引分配**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-28,2015-29</font>

&emsp;&emsp;把每个文件的所有盘块号都集中放在一起构成**索引块(表)**，每个文件都有其索引块，这是一个磁盘块地址的数组。索引块的第$i$个条目指向文件的第$i$个块。目录条包括索引块的地址。要读第$i$块，通过索引块的第$i$个条目的指针来查找和读入所需的块。

<img src="./操作系统/4.2.3-3.png" alt="4.2.3-3" style="zoom:90%;" />

- **解决索引块大小的机制**

  - **链接方式**：一个索引块通常为一个磁盘块，因此它本身能直接读写。为了处理大文件，可以将多个索引块链接起来。
  - **多层索引**：多层索引使用第一层索引块指向第二层索引块，第二层索引块再指向文件块。这种方法可以根据文件的大小继续到第三层或更高层。

  > 例如：4096B的块，能在索引块中存入1024个4B的指针，两层索引允许1048576个数据块，即允许的最大文件为4GB。

  - **混合索引**：将多种索引分配方式相结合的分配方式。例如：系统采用直接地址，又采用单级索引分配方式或两级索引分配方式。

<img src="./操作系统/4.2.3-4.png" alt="4.2.3-4" style="zoom:98%;" />

![4.2.3-5](./操作系统/4.2.3-5.png)



##### 2. 文件存储空间管理

**1）文件存储器空间的划分与初始化**。**一般来说，一个文件存储在一个文件卷中**。文件卷可以是物理盘的一部分，也可以是整个物理盘，支持超大型文件的文件卷也可以由多个物理盘组成。

<img src="./操作系统/4.2.3-6.png" alt="4.2.3-6" style="zoom:80%;" />

在一个文件卷中，文件**数据信息的空间(文件区)**和存放文件**控制信息FCB的空间(目录区)**是**分离**的。由于存在很多种类的文件表示和存放格式，所以现代操作系统中一般都有很多不同的文件管理模块，通过它们可以访问不同格式的逻辑卷中的文件，划分好目录区和文件区，建立空闲空间管理表格及存放逻辑卷信息的超级块。

**2）文件存储器空间管理**。文件存储设备分成许多大小相同的物理块，并以块为单位交换信息，因此，**文件存储设备的管理实际上是空闲块的组织和管理**，它包括空闲块的**组织、分配与回收**等问题。

- **空闲表法**

&emsp;&emsp;空闲表法属于**连续分配方式**，它与内存的动态分配方式类似，为每个文件分配一块连续的存储空间。**系统为外存上的所有空闲区建立一张空闲盘块表**，每个空闲区对应一个空闲表项，其中包括**表项序号、该空闲区第一个盘块号、该区的空闲盘块数**等信息。

<img src="./操作系统/4.2.3-7.png" alt="4.2.3-7" style="zoom:90%;" />

&emsp;&emsp;盘块的分配与内存的动态分配类似，采用首次适应算法、循环适应算法等。

- **空闲链表法**

&emsp;&emsp;将所有空闲盘区拉成一条空闲链，根据构成链所用的基本元素不同，可把链表分成两种形式：**空闲盘块链**和**空闲盘区链**。

&emsp;&emsp;空闲盘块链将盘块上所有的空闲空间以盘块为单位拉成一条链。**当用户因创建文件而请求分配存储空间时，系统从链首开始，依次摘下适当数目的空闲盘块分配给用户。当用户因删除文件而释放空间时，系统回收盘库依次插入空闲盘块链的末尾**。这种方法的优点是分配和回收一个盘块的过程非常简单，但在为一个文件分配盘块时可能要重复多次操作。

&emsp;&emsp;空闲盘区链将磁盘上所有**空闲盘区(每个盘区可包含若干盘块)**拉成一条链，在每个盘区上除含有用于**指示下一个空闲盘区的指针**外，还应有**指明本盘区的大小(盘块数)**的信息。分配盘区的方法与内存的动态分区分配类似，通常采用首次适应算法，在回收盘区时，同时也要将回收区域相邻的空闲盘区合并。

- **位示图法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-27,2015-31</font>

&emsp;&emsp;位示图利用二进制的一位来表示磁盘中的一个盘块的使用情况，盘块上所有的盘块都有一个二进制位与之对应。当其**值为“0”时，表示对应的盘块空闲；当其值为“1”时，表示对应的盘块被分配**。

<img src="./操作系统/4.2.3-8.png" alt="4.2.3-8" style="zoom:80%;" />

<img src="./操作系统/4.2.3-9.png" alt="4.2.3-9" style="zoom:80%;" />

**【注1】**位图法中没特殊要求的话行和列都是从1开始编号的。

**【注2】**
$$
盘块号 = 起始块号+ \lfloor 盘块号/每个盘块所占位数 \rfloor
$$

$$
块内字节号 = \lfloor (盘块号 \% 每个盘块所占位数)/8 \rfloor
$$

注意是字节号还是位号。



- **成组链接法**

&emsp;&emsp;**空闲表法和空闲链表法都不使用于大型文件系统，因为会使空闲表或空闲链表太大**。在UNIX系统中采用的是成组链接法，这种方法结合了空闲表和空闲链表两种方法，克服了表太大的缺点。

&emsp;&emsp;**思想**：把n个空闲扇区地址保存在第一个空闲扇区内，其后一个空闲扇区则保存另一顺序空闲扇区的地址，如此继续，直至所有空闲扇区均予以链接。**系统只需要保存一个指向第一个空闲扇区的指针**。假设磁盘最初全为空闲扇区，其成组链接如图所示，这种方式可以迅速找到大批空闲地址块。

<img src="./操作系统/4.2.3-10.png" alt="4.2.3-10" style="zoom:80%;" />

&emsp;&emsp;表示文件存储空闲空间的“位向量”表或第一个成组链块，以及卷中的目录区、文件区划分信息都需要存放在辅助存储器中，一般放在**卷头位置**，在UNIX系统中称为**超级块**。在对卷头中的文件进行操作前，超级块需要预先读入系统空闲的主存，并且经常保持主存超级块与辅存超级块的一致性。





### 4.3 磁盘组织与管理

#### 4.3.2 磁盘调度算法

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2013-21,2015-20</font>

<font color='#0099ff' size=5 face="黑体">大题：</font><font color='#FF0000' size=4 face="黑体">2010-45(C-SCAN)</font>

一次磁盘读写操作时间由**寻找(寻道)时间**、**延迟时间**和**传输时间**决定。

1）**寻找时间**$T_s$：活动头磁盘在读写信息前，将磁头移动到指定磁道所需的时间。这个时间除跨越$n$条磁道的时间外，还包括启动磁臂的时间$s$，即
$$
T_s = m \times n +s
$$
2）**延迟时间**$T_r$：磁头定位到某一磁道的扇区(块号)所需要的时间，设磁盘的旋转速度为$r$，则
$$
T_r = \frac{1}{2r}
$$

> 典型的旋转速度为5400转/分，相当于一周：
> $$
> \frac{1}{2r}=\frac{1 \times60 \times10^3ms}{2 \times 5400} \approx5.55ms
> $$

3）**传输时间**$T_t$：从磁盘读出或向磁盘写入数据所经历的时间，这个是时间取决于每次所读/写的字节数$b$和磁盘的旋转速度，即
$$
T_t = \frac{b}{rN}
$$
式中，$r$为磁盘每秒的旋转速度，$N$为一个磁盘上面的字节数。

目前常用的磁盘调度算法有以下几种：

**（1）先来先服务(FCFS)算法**

<img src="./操作系统/4.3.2-1.png" alt="4.3.2-1" style="zoom:80%;" />

> 例如，磁盘请求队列中的请求序分别为55,58,39,18,90,160,150,38,184，磁头的初始位置是磁道100，采用FCFS算法时磁头运动如图，磁头共移动了
> $$
> (45+3+19+21+72+70+10+112+146)=498
> $$
> 平均寻找长度 = 498/9 = 55.3

**（2）最短寻找时间优先(SSTF)算法**

SSTF算法是选择调度处理的磁道是当前磁头距离最近的磁道，以便使每次的寻找时间最短。**这种算法会产生“饥饿”现象**。

<img src="./操作系统/4.3.2-2.png" alt="4.3.2-2" style="zoom:80%;" />

>例如，磁盘请求队列中的请求序分别为55,58,39,18,90,160,150,38,184，磁头的初始位置是磁道100，采用SSTF算法时磁头运动如图，磁头共移动了
>$$
>10+32+3+16+1+20+132+10+24=248
>$$
>平均寻找长度 = 248/9 = 27.5

**（3）扫描(SCAN)算法(又称电梯调度算法)**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-29,2015-32</font>

<img src="./操作系统/4.3.2-3.png" alt="4.3.2-3" style="zoom:80%;" />

>例如，磁盘请求队列中的请求序分别为55,58,39,18,90,160,150,38,184，磁头的初始位置是磁道100。采用SCAN算法时，不但要知道磁头的当前位置，而且要知道磁头的移动方向，假设磁头沿磁道号增加的顺序移动，则移动磁道的顺序为100,150,160,184,200,90,58,55,39,38,18。磁头共移动了
>$$
>(50+10+24+16+110+32+3+16+1+20)=282
>$$
>平均寻道长度为 = 282/9 = 31.3

**（4）循环扫描(C-SCAN)算法**

在扫描算法的基础上规定磁头单向移动来提供服务，回返时直接快速移动至起始端而不服务任何请求。

<img src="./操作系统/4.3.2-4.png" alt="4.3.2-4" style="zoom:80%;" />

>例如，磁盘请求队列中的请求序分别为55,58,39,18,90,160,150,38,184，磁头的初始位置是磁道100。采用C-SCAN算法时，假设磁头沿磁道号增大的顺序移动，移动的顺序为100,150,160,184,200,0,18,38,39,55,58,90。磁头共移动了
>$$
>50+10+24+16+200+18+20+1+16+3+32=390
>$$
>平均寻道长度 = 390/9 = 43.33

- **LOOK调度**

<img src="./操作系统/4.3.2-5.png" alt="4.3.2-5" style="zoom:80%;" />

- **C-LOOK调度**

<img src="./操作系统/4.3.2-6.png" alt="4.3.2-6" style="zoom:80%;" />

**【注】4种磁盘调度算法的比较**

<img src="./操作系统/4.3.2-7.png" alt="4.3.2-7" style="zoom:80%;" />



#### 4.3.3 磁盘的管理

1. **改善磁盘设备I/O性能的方法**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2012-32</font>

① 重排I/O请求次序	② 预读和滞后写	③ 优化文件物理块的分布

2. **磁盘的初始化**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2017-29</font>

&emsp;&emsp;一个新的磁盘只是一个含有磁性记录材料的空白盘。**在磁盘能存储数据之前，它必须分成扇区以便磁盘控制器能进行读和写操作**，这个过程称为**低级格式化(物理分区)**。低级格 式化为磁盘的每个扇区采用特别的数据结构。每个扇区的数据结构通常由**头**、**数据区域**(通常是**512B**大小)和**尾部**组成。头部和尾部包含了一些磁盘控制器所用的信息。

&emsp;&emsp;为了使用磁盘存储文件，操作系统还需要将自己的数据结构记录在磁盘上：**第一步将磁盘分为由一个或多个柱面组成的分区(即我们熟悉的C盘、D盘等形式的分区)**；**第二步对物理分区进行逻辑格式化(创建文件系统)**，操作系统将初始的文件系统数据结构存储在磁盘上，这些数据结构包括空闲和已分配的空间及一个初始为空的目录。

3. **引导块**

&emsp;&emsp;计算机启动时需要运行一个**初始化(自举程序)**，它初始化**CPU、寄存器、设备控制器和内存**等，接着启动操作系统。为此，**该自举程序应找到磁盘上的操作系统内核，装入内存，并转到起始地址，从而开始操作系统的运行**。

&emsp;&emsp;**自举程序通常保存在ROM**中，为了避免改变自举代码需要改变ROM硬件的问题，故在ROM中保留很小的自举装入程序，将完整功能的自举程序保存在磁盘的启动块上，启动块位于磁盘的固定位。**拥有启动分区的磁盘称为启动磁盘或系统磁盘**。

4. **坏块**

&emsp;&emsp;由于磁盘有移动部件且容错能力弱，因此容易导致一个或多个扇区损坏。部分磁盘甚至从出厂时就有坏扇区。根据所使用的磁盘和控制器，对这些块有多种处理方法。

- **简单磁盘**

&emsp;&emsp;如**电子集成驱动器(IDE)**，坏扇区可**手工处理**，如MS-DOS的Format命令执行逻辑格式化时便会扫描磁盘以检查坏扇区。**坏扇区在FAT表上会注明**，因此程序不会使用。

- **复杂磁盘**

&emsp;&emsp;如**小型计算机系统接口(SCSI)**，其控制器维护一个**磁盘坏块链表**。该链表在出厂前进行低级格式化时就已经初始化，并在磁盘的整个使用过程中不断更新。低级格式化将一些块保留作为备用，对操作系统透明。**控制器可用备用块来逻辑地代替坏块**，这种方案称为**扇区备用**。

&emsp;&emsp;对坏块的处理实际上就是用某种机制，使系统不去使用坏块。**坏块属于硬件故障，操作系统是不能修复坏块的**。



## 第5章 输入/输出设备

### 5.1 I/O管理概述



#### 5.1.2 I/O控制方式

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2010-32,2013-22</font>

##### 1. 程序直接控制方式

&emsp;&emsp;计算机从外部设备读数据到存储器，每次读一个字的数据，对读入的每个字，CPU需要对外设状态进行循环检查，直到确定该字已经在I/O控制器的数据寄存器中。在程序直接控制方式下，由于CPU的高速性和I/O设备的低速性，致使CPU的绝大部分时间都处于等待I/O涉笔完成数据I/O的循环测试中，就是因为在CPU中未采取中断机构，使I/O设备无法向CPU报告它完成了一个字符的输入操作。

**特点：**CPU和I/O设备只能串行工作，CPU的利用率相对低。



##### 2. 中断驱动方式

&emsp;&emsp;中断驱动方式的思想是，允许I/O设备主动打断CPU的运行并请求服务，从而“解放”CPU。使得其向I/O控制器发送读命令后可以继续做其它有用的工作。

- **从I/O控制器的角度来看**

<img src="./操作系统/5.1.2-1.png" alt="5.1.2-1" style="zoom:90%;" />

- **从CPU的角度来看**

<img src="./操作系统/5.1.2-2.png" alt="5.1.2-2" style="zoom:90%;" />

**特点：**比程序直接控制更有效，但由于**数据中的每个字在存储器与I/O控制器之间的传输都必须经过CPU**，这就导致了中断驱动方式仍然会耗很多CPU时间。



##### 3. DMA方式

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2017-32</font>

&emsp;&emsp;DMA基本思想是在**I/O设备和内存之间开辟直接的数据通路**，彻底”解放“CPU。

- **DMA特点**

1）基本单位是**数据块**。

2）所传送的数据，是从设备直接送人内存的，或者相反。

3）仅在**传送一个或多个数据块的开始和结束时，才需CPU干预**，整块数据的传送是在DMA控制器的控制下完成的。

- **DMA控制器的组成**

<img src="./操作系统/5.1.2-3.png" alt="5.1.2-3" style="zoom:80%;" />

**1）命令/状态寄存器(CR)：**用于接收从CPU发来的I/O命令或有关控制信息，或设备的状态。

**2）内存地址寄存器(MAR)：**在输入时，它存放把数据从设备传送到内存的起始目标地址，在输出时，它存放由内存到设备的内存源地址。

**3）数据寄存器(DR)：**用于暂存从设备到内存或内存到设备的数据。

**4）数据计数器(DC)：**存放本次要传送的字(节)数。

- **DMA工作过程**

<img src="./操作系统/5.1.2-4.png" alt="5.1.2-4" style="zoom:85%;" />

- **DMA控制方式 VS 中断I/O方式**

1）中断驱动方式在每个数据需要传输时中断CPU，而DMA控制方式是在所要求传送一批数据全部结束时才中断CPU。

2）中断驱动方式数据传送是在中断处理时由CPU控制完成的，而DMA控制方式则是在DMA控制器的控制下完成的。

3）中断I/O方式请求的是CPU的处理时间，DMA方式请求的是总线的使用权。

4）中断I/O响应发生在一条指令执行结束后，DMA响应发生在一个总线事务完成后。

5）中断I/O方式下数据传送通过软件完成，DMA方式下数据传送由硬件完成。

<img src="./操作系统/5.1.2-5.png" alt="5.1.2-5" style="zoom:80%;" />



##### 4. 通道控制方式

&emsp;&emsp;I/O通道是专门负责输入/输出的处理机。I/O通道方式是DMA方式的发展，它**可以减少CPU的干预**，即把对一个数据块的读(或写)为单位的干预，减少为对一组数据块的读(或写)及又换控制和管理为单位的干预。同时又可以**实现CPU、通道和I/O设备三者的并行操作**，从而更有效地提高整个系统的资源利用率。

- **I/O通道与一般处理器的区别**

1）通道指令的类型单一

2）没有自己的内存

3）通道执行的通道程序是放在主机的内存中的，也就是说**通道与CPU共享内存**

- **I/O通道与DMA方式的区别**

1）DMA方式需要CPU来控制传输的数据块大小、传输的内存位置，而通道方式中的这些信息是由通道控制的

2）每个DMA控制器对应**一台设备**与内存传递数据，而一个通道可以控制**多台设备**与内存的数据交换



#### 5.1.3 I/O子系统的层次结构

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2011-26,2012-26,2013-25</font>

![5.1.3-1](./操作系统/5.1.3-1.png)

（1）**用户I/O软件**：实现与用户交互的接口，用户可直接调用在用户层提供的、与I/O操作有关的库函数，对设备进行操作。一般而言，大部分的I/O软件都在操作系统内部，但仍有一小部分在用户层，用户层软件必须通过一组系统调用来获得操作系统的服务。

（2）**设备独立性软件**：设备独立性也称为设备无关性，使得应用程序独立于具体使用的物理设备，为实现设备独立性引用了**逻辑设备**和**物理设备**两个概念。

逻辑设备的好处是：①**增加设备分配的灵活性**；②**易于实现I/O重定向**，指用于I/O操作的设备可以更换，而不必改变应用程序。

设备独立性软件的主要功能有：①**执行所以设备的公有操作**。②**向用户层(或文件层)提供统一接口**。

（3）**设备驱动程序**：与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动I/O设备工作的驱动程序。没类设备配置一个设备驱动程序，通常以**进程**的形式存在。

（4）**中断处理程序**：用于保存被中断进程的CPU环境，转入相应的中断处理程序进行处理，处理完并恢复被中断进程的现场后，返回到被中断进程。

**任务**：进行上下文切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等。

（5）**硬件设备**：I/O设备通常包括一个**机械部件**和一个**电子部件**。电子部件称为**设备控制器**(或**适配器**)。

- 设备控制器的**主要功能**如下：

①**接收和识别CPU或通道发来的命令**，如磁盘控制器能接收读、写、查找等命令。

②**实现数据交换**，包括设备与控制器之间的数据传输；通过数据总线或通道，控制器和主存之间的数据传输。

③**发现和记录设备及自身的状态信息**，供CPU处理使用。

④**设备地址识别**。

- 设备控制器的主要**组成部分**

①**设备控制器与CPU的接口**。该接口有三类信号线：数据线、地址线和控制线。

②**设备控制器与设备的接口**。一个接口连接一台设备，每个接口中都存在数据、状态和控制三种类型的信号。

③**I/O控制逻辑**。用于实现对设备的控制。



### 5.2 I/O核心子系统



#### 5.2.3 高速缓存与缓冲区

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2011-31,2016-28</font>

1. **高速缓存**

&emsp;&emsp;磁盘高速缓存**逻辑上属于磁盘**，**物理上则是驻留在内存中的盘块**。高速缓存在内存中分为两种形式：一种是**在内存中开辟一个单独的存储空间**作为磁盘高速缓存，大小固定；另一种是是**把未利用的内存空间作为一个缓冲池**，供请求分页系统和磁盘I/O时共享。

2. **缓冲区**

- **目的**

1）缓和CPU与I/O设备间速度不匹配的矛盾。

2）减少CPU的中断频率，放宽对CPU响应时间的限定。

3）解决基本数据单元大小(即数据粒度)不匹配的问题。

4）提高CPU和I/O设备之间的并行性。

- **方法**

  **1）硬件缓冲器**	**2）缓冲区(位于内存区域)**

**缓冲区特点**：当缓冲区的数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出；当缓冲区为空时，可以往缓冲区冲入数据，但必须把缓冲区充满后，才能从缓冲区把数据传出。

假设从磁盘把一块**数据输入缓冲区的时间**为$T$，操作系统**将该缓冲区中的数据传输到用户区的时间**为$M$，而CPU对这**一块数据处理的时间**为$C$。

**（1）单缓冲**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2013-27</font>

处理每块数据的用时为
$$
\max(C,T)+M
$$
**（2）双缓冲**

处理每块数据的用时为
$$
\max(C+M,T)
$$
当$C+M < T$时，则可使设备连续输入；若$C+M>T$时，则可以使CPU不必等待设备输入。

**（3）循环缓冲**

&emsp;&emsp;包含多个大小相等的缓冲区，每个缓冲区中有一个链接指针指向下一个缓冲区，最后一个缓冲区指针指向第一个缓冲区，多个缓冲区构成一个环。

&emsp;&emsp;需要两个指针in和out，int指针指向可以输入数据的第一个空缓冲区；out指针指向可以提取一个装满数据的缓冲区。

**（4）缓冲池**

由多个系统共用的缓冲区组成，缓冲区按其使用情况可以形成三个队列：**空缓冲队列**、**装满输入缓冲队列(输入队列)**和**装满输出数据队列(输出队列)**。

![5.2.3-1](./操作系统/5.2.3-1.png)

3. **高速缓存与缓冲区的对比**

![5.2.3-2](./操作系统/5.2.3-2.png)



#### 5.2.4 设备分配与回收

1. **设备的分配概述**

&emsp;&emsp;设备分配是根据用户的I/O请求分配所需的设备。**分配的总原则是充分发挥设备的使用效率，尽可能让设备忙碌，又要避免由于不合理的分配方法造成进程死锁**。

- 以下使用方式的设备分别称为**独占设备**、**共享设备**和**虚拟设备**。

**1）独占式使用设备**：指在申请设备时，若设备空闲，则将其独占，不允许其他进程申请使用，直到设备被释放为止。例如：**打印机**。

**2）分时式共享使用设备**：例如**对磁盘设备的I/O操作**，各进程的每次I/O操作请求可以通过分时来交替进行。

**3）以SPOOLing方式使用外部设备**：SPOOLing技术是在**批处理操作系统**时代引入的，即**假脱机I/O技术**。这种技术对于设备的操作，实际上就是对I/O设备进行批处理。**SPOOLing是一种以空间换时间的技术**。

**【注】**页面调度算法是以时间换空间。

2. **设备分配的数据结构**

&emsp;&emsp;设备分配依据主要数据结构有**设备控制表(DCT)**、**控制器控制表(COCT)**、**通道控制表(CHCT)**和**系统设备表(SDT)**。

- **设备控制表(DCT)**

&emsp;&emsp;一个设备控制表表征一个设备，而这个控制表中的表项就是设备的各个属性。

&emsp;&emsp;每个设备部分分为**机械部件**和**电子部件**两部分，其中负责解析上层传达的命令并控制机械部件运作的是电子部件(控制器)，所以**每个DCT都需要一个表项来表示控制器**，即需要一个指向控制器控制表(COCT)的指针。因此**DCT与COCT有一一对应的关系**。

<img src="./操作系统/5.2.4-1.png" alt="5.2.4-1" style="zoom:80%;" />

- **控制器控制表(COCT)**和**通道控制表(CHCT)**

&emsp;&emsp;现代操作系统的I/O控制大多采用通道控制，而设备控制器又需要请求它服务，因此**每个COCT必定有一个表项存放指向相应通道控制表CHCT的指针**，而一个通道可以为多个设备服务，因此CHCT中必然有一个指针指向一个表，这个表上的信息表达的是CHCT提供服务的设备控制器，**CHCT和COCT是一对多的关系**。

- **系统设备表(SDT)**

&emsp;&emsp;**整个系统只有一张SDT**，它记录已连接到系统中的所有物理设备情况。

<img src="./操作系统/5.2.4-2.png" alt="5.2.4-2" style="zoom:85%;" />



3. **设备分配的策略**

**1）设备分配原则**：充分发挥设备的使用效率，尽可能让设备忙碌，又要避免由于不合理的分配方法造成进程死锁，还要**将用户程序和具体设备隔离开**。

**2）设备分配方式**

**① 静态分配**：主要**用于独立设备的分配**，在用户作业开始执行前，由系统一次性分配该作业要求的所有设备、控制器(如通道等)。一旦分配，这些设备、控制器就一直被该作业使用，直到该作业被撤销。

**【注】**静态分配**不会出现死锁现象**，但设备的使用效率低，不符合分配原则。

**② 动态分配**：在进程执行过程中根据执行需求进行。当进程需要设备时，通过系统调用命令向系统发出设备请求，由系统按照事先规定的策略给进程分配所需的设备、I/O控制器，一旦用完会造成立即释放。

**【注1】**动态分配方式有利提高设备的使用效率，但若**分配算法不当会造成死锁**。

**【注2】**常用的动态设备分配算法有**先请求先服务**、**优先级高者优先**等。

**3）设备分配算法**

① 独占设备既可以使用动态分配方式又可以采用静态分配方式，往往采用静态分配方式。

② 共享设备可被多个进程所共享，一般采用动态分配方式，但在每个I/O传输时间内只能被一个进程所占有，通常采用先请求先服务**、**优先级高者优先。



4. **设备分配的安全性**

设备分配的安全性是指设备分配中应防止发生进程死锁。

**1）安全分配模式**：每当进程发出I/O请求后便进入阻塞态，直到其I/O操作完成时才被唤醒。这样一旦进程获得某种设备后便阻塞，不能再请求任何资源，而且在它阻塞时也不保持任何资源。

**优点**：设备分配安全

**缺点**：CPU和I/O设备是串行工作的(对同一进程而言)

**2）不安全分配方式**：进程在发出I/O请求后继续运行，需要时发出第二个、第三个I/O请求等，仅当进程所请求的设备已经被另一进程占用时，才进入阻塞态。

**优点**：一个进程可以同时操作多个设备，从而迅速推进进程

**缺点**：这种设备分配又可能产生死锁



5. **逻辑设备名到物理设备名的映射**

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2009-32</font>

&emsp;&emsp;为了提高设备分配的灵活性和设备的利用率，方便实现I/O重定向，引入了设备独立性。**设备独立性是指程序独立于具体使用的物理设备**。

&emsp;&emsp;为了实现设备独立性，在应用程序中使用**逻辑设备名**来请求使用某类设备，在系统中设置一张**逻辑设备表(LUT)**，用于将逻辑设备名映射为物理设备名。

&emsp;&emsp;LUT表项包括**逻辑设备名**、**物理设备名**和**设备驱动程序入口地址**。当进程用逻辑设备名来请求分配设备时，系统为它分配相应的物理设备，并在LUT中建立一个表项，以后进程再利用逻辑设备名请求I/O操作时，系统查找LUT来寻找相应的物理设备和驱动程序。

&emsp;&emsp;系统中可采取两种方式建立逻辑设备表：

**1）在整个系统中只设置一张LUT**：所有进程的设备分配情况都记录在这张表中，故**不允许有相同的逻辑设备名，主要使用于单用户系统**。

**2）为每个用户设置一张LUT**：当用户登录时，系统便为该用户建立一个进程，同时也为之建立一张LUT，并**把该表放入进程的PCB**。



#### 5.2.5 SPOOLing技术(假脱机技术)

<font color='#0099ff' size=5 face="黑体">选择：</font><font color='#FF0000' size=4 face="黑体">2016-31</font>

&emsp;&emsp;为了缓和CPU的高速性与I/O设备低速性之间的矛盾，引入脱机输入/输出技术。该技术利用了专门的**外围控制机**，将低速I/O设备上的数据传送到高速磁盘上，或者相反。SPOOLing的意思是外部设备同时联机操作，又称假脱机输入/输出操作，**是操作系统中采用的一项将独占设备改成共享设备的技术**。

<img src="./操作系统/5.2.5-1.png" alt="5.2.5-1" style="zoom:80%;" />

1. **输入并和输出并**

&emsp;&emsp;输入并和输出并是指**在磁盘上开辟出的两个存储区域**。输入并模拟脱机时输入时的磁盘，用于收容I/O设备输入的数据。输出并模拟脱机输出时的磁盘，用于收容用户程序的输出数据。

2. **输入缓冲区和输出缓冲区**

&emsp;&emsp;输入缓冲区和输出缓冲区是**在内存中**开辟的两个缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再送到输入并。输出缓冲区用于暂存从输出并送来的数据，以后再传送到输出设备。

3. **输入进程和输出进程**

- **输入进程**：模拟脱机输入时的外围控制机。将用户要求的数据从输入机通过输入缓冲区再送到输入并。当CPU需要输入数据时，直接将数据从输入并读入内存。
- **输出进程**：模拟脱机输出时的外围控制机，把用户要求输出的数据先从内存送到输出并，待输出设备空闲时，再将输出并中的数据经过输出缓冲送到输出设备。

- **例子**

**共享打印机**：当用户进程请求打印时，SPOOLing系统同意为它打印输出，但并不真正立即把打印机分配给该用户进程，而只为它做两件事：

1）由输出进程在输出并中为之申请一个空闲磁盘块区，并将要打印的数据送入其中。

2）输出进程再为用户进程申请一张空白用户请求打印表，并将用户的打印要求填入其中，再将该表挂到请求打印队列上。

- **SPOOLing如何做到牺牲空间换取时间的**

<img src="./操作系统/5.2.5-2.png" alt="5.2.5-2" style="zoom:80%;" />

